import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Ellipse
from scipy.stats import multivariate_normal
import random

plt.style.use('seaborn')

# Generate some demonstration data
def generate_X(true_Mu, true_Var):
    num1, mu1, var1 = 400, true_Mu[0], true_Var[0]
    X1 = np.random.multivariate_normal(mu1, np.diag(var1), num1)

    num2, mu2, var2 = 600, true_Mu[1], true_Var[1]
    X2 = np.random.multivariate_normal(mu2, np.diag(var2), num2)

    num3, mu3, var3 = 1000, true_Mu[2], true_Var[2]
    X3 = np.random.multivariate_normal(mu3, np.diag(var3), num3)

    X = np.vstack((X1, X2, X3))

    return X


# update the value of W
def update_W(X, Mu, Var, Pi):
    n_points, n_clusters = len(X), len(Pi)
    pdfs = np.zeros(((n_points, n_clusters)))
    for i in range(n_clusters):
        pdfs[:, i] = Pi[i] * multivariate_normal.pdf(X, Mu[i], np.diag(Var[i]))
    W = pdfs / pdfs.sum(axis=1).reshape(-1, 1)
    return W


# update the value of Pi
def update_Pi(W):
    Pi = W.sum(axis=0) / W.sum()
    return Pi


# Calculate the loglikelyhood function
def logLH(X, Pi, Mu, Var):
    n_points, n_clusters = len(X), len(Pi)
    pdfs = np.zeros(((n_points, n_clusters)))
    for i in range(n_clusters):
        pdfs[:, i] = Pi[i] * multivariate_normal.pdf(X, Mu[i], np.diag(Var[i]))
    return np.mean(np.log(pdfs.sum(axis=1)))


# Plot the aggregation scatter plot
def plot_clusters(X, Mu, Var, Mu_true=None, Var_true=None):
    colors = ['b', 'g', 'r']
    n_clusters = len(Mu)

    plt.scatter(X[:, 0], X[:, 1], s=5)
    ax = plt.gca()
    for i in range(n_clusters):
        plot_args = {'fc': 'None', 'lw': 2, 'edgecolor': colors[i], 'ls': ':'}
        ellipse = Ellipse(Mu[i], 3 * Var[i][0], 3 * Var[i][1], **plot_args)
        ax.add_patch(ellipse)
    if (Mu_true is not None) & (Var_true is not None):
        for i in range(n_clusters):
            plot_args = {'fc': 'None', 'lw': 2, 'edgecolor': colors[i], 'alpha': 0.5}
            ellipse = Ellipse(Mu_true[i], 3 * Var_true[i][0], 3 * Var_true[i][1], **plot_args)
            ax.add_patch(ellipse)         



# Update the value of Mu
def update_Mu(X, W):
    n_clusters = W.shape[1]
    Mu = np.zeros((n_clusters, 2))
    for i in range(n_clusters):
        Mu[i] = np.average(X, axis=0, weights=W[:, i])
    return Mu


# Update the value of Var
def update_Var(X, Mu, W):
    n_clusters = W.shape[1]
    Var = np.zeros((n_clusters, 2))
    for i in range(n_clusters):
        Var[i] = np.average((X - Mu[i]) ** 2, axis=0, weights=W[:, i])
    return Var

def fit_data(data,n_cluster,epoch = 55,plot = False):
    X = data
    n_points = len(X)
    x_dim = len(data[0])
    Mu = 3*np.random.normal(np.zeros([n_cluster,x_dim]),np.ones([n_cluster,x_dim]))
    Var =3* np.random.random([n_cluster,x_dim])
    
    Pi = [1 / n_cluster] * n_cluster
    W = np.ones((n_points, n_cluster)) / n_cluster 
    Pi = W.sum(axis=0) / W.sum()
    # Iteration
    loglh = []
    if plot:
        plt.ion()

    for i in range(epoch):
        # Calculate the LogLikelyhood function
        if plot:
            plt.cla()
            plot_clusters(X, Mu, Var)
            plt.pause(0.1)
        
        loglh.append(logLH(X, Pi, Mu, Var))

        # E step: Expectation value
        W = update_W(X, Mu, Var, Pi)

        # M step: Maximize the expecation value
        Pi = update_Pi(W)
        Mu = update_Mu(X, W)
        print('log-likehood:%.3f'%loglh[-1])
        Var = update_Var(X, Mu, W)
    
    if plot:
        plt.ion()

    return Mu, Var


def demo():
    # Generate some data
    true_Mu = [[-3, -0.5], [5.5, -5.5], [3, 5]]
    true_Var = [[1, 3], [2, 2], [3, 2]]
    X = generate_X(true_Mu, true_Var)
    # 初始化
    n_clusters = 3
    print(X)
    u,v = fit_data(X,3, 55 , True)
    print(u)
    print(v)
"""
代词: 明确主体
单词: 玩大蛇
时态: 注意动词
标点: 老老实实修饰语

13738067956
"""
